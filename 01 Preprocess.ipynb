{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce597c-2d06-401f-a212-ac4ecf82d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from mne import create_info\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_meg_data(hdf5_file_path):\n",
    "    with h5py.File(hdf5_file_path, 'r') as f:\n",
    "        raw_data = f['data'][:] # Load raw_data as a NumPy array\n",
    "        times = f['times'][:]\n",
    "    if len(times) >= 2:\n",
    "        dt = times[1] - times[0]\n",
    "        sfreq = 1.0 / dt\n",
    "    else:\n",
    "        raise ValueError(\"Not enough time points in 'times' to determine sampling frequency.\")\n",
    "    n_channels = raw_data.shape[0]\n",
    "    channel_names = [f'MEG {i+1:03d}' for i in range(n_channels)]\n",
    "    info = create_info(ch_names=channel_names, sfreq=sfreq, ch_types=['mag'] * n_channels)\n",
    "    return raw_data, info # raw_data is already a numpy array here\n",
    "\n",
    "def generate_meg_labels(tsv_data, info, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Generates 0/1 speech/silence labels aligned to MEG sfreq, without visualization.\n",
    "\n",
    "    Parameters:\n",
    "        - tsv_data: DataFrame with timing and labeling information.\n",
    "        - info: MNE Info object containing metadata (including sampling frequency).\n",
    "        - start_time, end_time: Time window (in seconds) to generate labels for.\n",
    "\n",
    "    Returns:\n",
    "        - aligned_labels: NumPy array of 0/1 labels, sampled at info['sfreq'].\n",
    "    \"\"\"\n",
    "    tsv_data = tsv_data.copy()\n",
    "    tsv_data['timemeg'] = tsv_data['timemeg'].astype(float)\n",
    "\n",
    "    # Ensure start_time is covered by adding a preceding entry if necessary\n",
    "    last_before = tsv_data[tsv_data['timemeg'] < start_time]\n",
    "    if not last_before.empty:\n",
    "        last_before = last_before.iloc[-1:]\n",
    "    else: # If no events before start_time, assume silence starts from start_time\n",
    "        last_before = pd.DataFrame({'timemeg': [start_time - 0.001], 'kind': ['silence'], 'segment': ['']}) # A dummy entry\n",
    "\n",
    "    window_data = tsv_data[(tsv_data['timemeg'] >= start_time) & (tsv_data['timemeg'] <= end_time)]\n",
    "    filtered_data = pd.concat([last_before, window_data]).sort_values('timemeg').drop_duplicates(subset=['timemeg'], keep='first')\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        # Handle empty window: assume silence\n",
    "        filtered_data = pd.DataFrame({'timemeg': [start_time, end_time], 'kind': ['silence', 'silence']})\n",
    "\n",
    "    filtered_data['speech_label'] = 0\n",
    "    filtered_data.loc[filtered_data['kind'].isin(['word', 'phoneme']), 'speech_label'] = 1\n",
    "\n",
    "    sfreq = info['sfreq']\n",
    "    # Calculate the number of samples, rounding up to ensure the end time is included if needed, \n",
    "    # but the time calculation based on end_time - start_time should be sufficient if rounding issues are minimal.\n",
    "    num_samples = int((end_time - start_time) * sfreq) \n",
    "    \n",
    "    # Handle cases where num_samples might be 0 or negative\n",
    "    if num_samples <= 0:\n",
    "        print(f\"Warning: Time window too small or invalid ({start_time}-{end_time}s) for sfreq {sfreq}Hz. Returning empty labels.\")\n",
    "        return np.array([])\n",
    "\n",
    "    aligned_labels = np.zeros(num_samples, dtype=np.float32)\n",
    "\n",
    "    # Fill labels based on time segments\n",
    "    # Initialize current_label from the first valid point\n",
    "    if not filtered_data.empty:\n",
    "        # Find the first entry whose timemeg is >= start_time, or use the very first entry if none\n",
    "        initial_entries = filtered_data[filtered_data['timemeg'] >= start_time]\n",
    "        if not initial_entries.empty:\n",
    "            current_label = initial_entries.iloc[0]['speech_label']\n",
    "            first_event_time = initial_entries.iloc[0]['timemeg']\n",
    "            # Fill from start_time up to first_event_time with current_label\n",
    "            first_sample_idx = max(0, int((start_time - start_time) * sfreq))\n",
    "            end_of_first_segment_sample_idx = min(num_samples, int((first_event_time - start_time) * sfreq))\n",
    "            if first_sample_idx < end_of_first_segment_sample_idx:\n",
    "                aligned_labels[first_sample_idx:end_of_first_segment_sample_idx] = current_label\n",
    "        # Note: If initial_entries is empty, it means all events are *before* start_time. \n",
    "        # The logic below handles this by relying on the 'last_before' entry to set the initial state.\n",
    "\n",
    "\n",
    "    for i in range(len(filtered_data)):\n",
    "        row = filtered_data.iloc[i]\n",
    "        event_time = row['timemeg']\n",
    "        label_at_event = row['speech_label']\n",
    "\n",
    "        # Determine the start and end sample index for the current segment\n",
    "        # This segment starts at the current event_time and continues until the next event_time or end_time\n",
    "        start_sample_idx = max(0, int((event_time - start_time) * sfreq))\n",
    "\n",
    "        if i + 1 < len(filtered_data):\n",
    "            next_event_time = filtered_data.iloc[i+1]['timemeg']\n",
    "            end_sample_idx = min(num_samples, int((next_event_time - start_time) * sfreq))\n",
    "        else:\n",
    "            end_sample_idx = num_samples # Until the end of the window\n",
    "\n",
    "        # Fill the segment starting from this event_time with the label that *starts* at this event\n",
    "        if start_sample_idx < end_sample_idx:\n",
    "            # The label should be valid from start_sample_idx up to (but not including) end_sample_idx\n",
    "            aligned_labels[start_sample_idx:end_sample_idx] = label_at_event\n",
    "\n",
    "    return aligned_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fcc8f-fb59-4eda-ad52-16e7b81ce1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- SENSORS SPEECH MASK ---\n",
    "SENSORS_SPEECH_MASK = [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
    "                       45, 46, 47, \n",
    "                       120, 121, 122,\n",
    "                       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, \n",
    "                       174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
    "                       198, 199, 200,\n",
    "                       271, 272, 273, 274, 275, 276]\n",
    "\n",
    "# --- Batch processing logic (modified to save NumPy arrays) ---\n",
    "base_folder = \"./libribrain/phoneme/data\" # Replace with your root folder path\n",
    "output_labels_folder = \"./libribrain/data/labels_npy\" # Change to the folder where you saved the .npy tags\n",
    "output_meg_data_folder = \"./libribrain/data/meg_data_npy\" # Change to the folder where the .npy MEG data is saved\n",
    "os.makedirs(output_labels_folder, exist_ok=True)\n",
    "os.makedirs(output_meg_data_folder, exist_ok=True) # Create a folder to save MEG data\n",
    "\n",
    "print(f\"Base folder: {base_folder}\")\n",
    "print(f\"Output Labels folder: {output_labels_folder}\")\n",
    "print(f\"Output MEG Data folder: {output_meg_data_folder}\")\n",
    "print(f\"SENSORS_SPEECH_MASK applied: {SENSORS_SPEECH_MASK}\")\n",
    "print(\"MEG data will be scaled by dividing by 1e-07.\")\n",
    "\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\"_meg.h5\"):\n",
    "            hdf5_file_path = os.path.join(root, file)\n",
    "\n",
    "            # Build the corresponding TSV file path\n",
    "            parts = hdf5_file_path.split(os.sep)\n",
    "            # Find the index of the 'serialised' folder and replace it with 'events'\n",
    "            try:\n",
    "                serialised_idx = parts.index('serialised')\n",
    "                tsv_parts = parts[:serialised_idx] + ['events'] + parts[serialised_idx + 1:]\n",
    "                # Replace file name\n",
    "                tsv_file_name = file.replace('_proc-bads+headpos+sss+notch+bp+ds_meg.h5', '_events.tsv')\n",
    "                tsv_parts[-1] = tsv_file_name\n",
    "                tsv_file_path = os.path.join(*tsv_parts)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping {hdf5_file_path}: 'serialised' folder not found in path for TSV inference.\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(tsv_file_path):\n",
    "                print(f\"Corresponding TSV file not found for: {tsv_file_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nProcessing MEG: {hdf5_file_path}\")\n",
    "            print(f\"With TSV: {tsv_file_path}\")\n",
    "\n",
    "            try:\n",
    "                tsv_data = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "                meg_raw_np, info = load_meg_data(hdf5_file_path) # meg_raw_np is already a numpy array\n",
    "\n",
    "                # Get the total duration of MEG data to generate a complete label sequence\n",
    "                total_meg_samples = meg_raw_np.shape[1]\n",
    "                total_duration = total_meg_samples / info['sfreq']\n",
    "\n",
    "                # --- 1. Generate and save the label (save as .npy) ---\n",
    "                aligned_labels_np = generate_meg_labels(tsv_data, info, start_time=0, end_time=total_duration)\n",
    "\n",
    "                if aligned_labels_np.size > 0:\n",
    "                    # Defines the name of the file where the tags are saved\n",
    "                    output_label_filename = os.path.basename(file).replace('_proc-bads+headpos+sss+notch+bp+ds_meg.h5', '_labels.npy')\n",
    "                    output_label_full_path = os.path.join(output_labels_folder, output_label_filename)\n",
    "                    aligned_labels_np = aligned_labels_np.reshape(1, -1) \n",
    "                    np.save(output_label_full_path, aligned_labels_np) # Save as NumPy .npy\n",
    "                    print(f\"Successfully saved labels (shape {aligned_labels_np.shape}) to: {output_label_full_path}\")\n",
    "                else:\n",
    "                    print(f\"No labels generated for {hdf5_file_path}. Skipping label save.\")\n",
    "\n",
    "                # --- 2. Filter, scale, and save raw MEG data (save as .npy) ---\n",
    "                \n",
    "                # a. Channel Filtering\n",
    "                meg_masked_np = meg_raw_np[SENSORS_SPEECH_MASK, :]\n",
    "                print(f\"Original MEG shape: {meg_raw_np.shape}, Masked MEG shape: {meg_masked_np.shape}\")\n",
    "\n",
    "                # b. Scaling\n",
    "                # 除以 1e-07，即乘以 1e+07\n",
    "                scaling_factor = 1e-07\n",
    "                meg_scaled_np = meg_masked_np / scaling_factor\n",
    "                \n",
    "                # 定义MEG数据保存文件的名称\n",
    "                output_meg_filename = os.path.basename(file).replace('.h5', '_masked_scaled.npy')\n",
    "                output_meg_full_path = os.path.join(output_meg_data_folder, output_meg_filename)\n",
    "\n",
    "                np.save(output_meg_full_path, meg_scaled_np.astype(np.float32)) # Save as NumPy .npy\n",
    "                print(f\"Successfully saved masked and scaled MEG data (shape {meg_scaled_np.shape}) to: {output_meg_full_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {hdf5_file_path} or {tsv_file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "print(\"\\nBatch processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df362b-8ab1-404e-892e-6ffb9304ab14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
