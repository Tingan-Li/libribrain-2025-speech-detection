{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06196f-d739-4fbf-8091-f628dd2daee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from scipy.interpolate import interp1d\n",
    "import typing as tp\n",
    "import random\n",
    "\n",
    "# You MUST ensure these are defined or imported in your actual environment.\n",
    "from seanet_style import SEANetTransformerClassifier, create_mask \n",
    "\n",
    "# --- Dataset Classes ---\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, input_files, output_files, min_window=1000, max_window=4000,\n",
    "                 noise_stds=1e-6, transform_probability=0.95, step_size=50,\n",
    "                 channel_wise_noise_stds=None,\n",
    "                 scale_range=(0.9, 1.1),\n",
    "                 num_warp_knots=4,\n",
    "                 warp_scale=0.1):\n",
    "        self.input_files = input_files\n",
    "        self.output_files = output_files\n",
    "        assert len(self.input_files) == len(self.output_files), \"Input and output file counts mismatch.\"\n",
    "\n",
    "        self.file_metadata = []\n",
    "        # Use np.load(f, mmap_mode='r') to save memory\n",
    "        self.input_memmaps = [np.load(f, mmap_mode='r') for f in self.input_files]\n",
    "        self.output_memmaps = [np.load(f, mmap_mode='r') for f in self.output_files]\n",
    "\n",
    "        self.min_window = min_window\n",
    "        self.max_window = max_window\n",
    "        self.step_size = step_size\n",
    "        self.valid_window_sizes = list(range(min_window, max_window + 1, step_size))\n",
    "        if not self.valid_window_sizes:\n",
    "            self.valid_window_sizes = [min_window]\n",
    "\n",
    "        self.noise_stds = noise_stds\n",
    "        self.transform_prob = transform_probability\n",
    "        self.channel_wise_noise_stds = channel_wise_noise_stds\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "        self.num_warp_knots = num_warp_knots\n",
    "        self.warp_scale = warp_scale\n",
    "\n",
    "        self.total_windows = 0\n",
    "        for i, (inp_mmap, out_mmap) in enumerate(zip(self.input_memmaps, self.output_memmaps)):\n",
    "            channels, length = inp_mmap.shape\n",
    "\n",
    "            num_windows_in_file = 0\n",
    "            if length >= self.min_window:\n",
    "                # Simple calculation of windows based on min_window and step_size\n",
    "                num_windows_in_file = (length - self.min_window) // self.step_size + 1\n",
    "\n",
    "            self.file_metadata.append({\n",
    "                'input_shape': inp_mmap.shape,\n",
    "                'output_shape': out_mmap.shape,\n",
    "                'length': length,\n",
    "                'channels': channels,\n",
    "                'num_windows': num_windows_in_file,\n",
    "                'start_idx_offset': self.total_windows\n",
    "            })\n",
    "            self.total_windows += num_windows_in_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_windows\n",
    "\n",
    "    def _time_warp(self, input_tensor, output_tensor):\n",
    "        \"\"\"\n",
    "        Applies time warping to the input and output tensors.\n",
    "        input_tensor: (C, L)\n",
    "        output_tensor: (C', L)\n",
    "        \"\"\"\n",
    "        length = input_tensor.shape[1]\n",
    "        t = np.linspace(0, 1, length)\n",
    "\n",
    "        knots_x = np.linspace(0, 1, self.num_warp_knots)\n",
    "        knots_y = knots_x + np.random.normal(0, self.warp_scale, self.num_warp_knots)\n",
    "        knots_y = np.sort(knots_y)\n",
    "\n",
    "        knots_y[0] = 0\n",
    "        knots_y[-1] = 1\n",
    "\n",
    "        warp_func = interp1d(knots_x, knots_y, kind='cubic', fill_value=\"extrapolate\")\n",
    "        warped_t = warp_func(t)\n",
    "        warped_t = np.clip(warped_t, 0, 1)\n",
    "\n",
    "        warped_input_channels = []\n",
    "        for i in range(input_tensor.shape[0]):\n",
    "            interp_func = interp1d(t, input_tensor[i, :].numpy(), kind='linear', fill_value=\"extrapolate\")\n",
    "            warped_input_channels.append(interp_func(warped_t))\n",
    "        warped_input = torch.from_numpy(np.array(warped_input_channels)).float()\n",
    "\n",
    "        warped_output_channels = []\n",
    "        for i in range(output_tensor.shape[0]):\n",
    "            interp_func = interp1d(t, output_tensor[i, :].numpy(), kind='linear', fill_value=\"extrapolate\")\n",
    "            warped_output_channels.append(interp_func(warped_t))\n",
    "        warped_output = torch.from_numpy(np.array(warped_output_channels)).float()\n",
    "\n",
    "        # Reshape/pad to original length L\n",
    "        if warped_input.shape[1] < length:\n",
    "            pad_amount = length - warped_input.shape[1]\n",
    "            warped_input = F.pad(warped_input, (0, pad_amount), 'constant', 0)\n",
    "            warped_output = F.pad(warped_output, (0, pad_amount), 'constant', 0)\n",
    "        elif warped_input.shape[1] > length:\n",
    "            warped_input = warped_input[:, :length]\n",
    "            warped_output = warped_output[:, :length]\n",
    "        \n",
    "        threshold = 0.5\n",
    "        warped_output = (warped_output > threshold).float()\n",
    "        return warped_input, warped_output\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_offset = 0\n",
    "        file_idx = -1\n",
    "        local_idx = -1\n",
    "        for i, meta in enumerate(self.file_metadata):\n",
    "            if idx < current_offset + meta['num_windows']:\n",
    "                file_idx = i\n",
    "                local_idx = idx - current_offset\n",
    "                break\n",
    "            current_offset += meta['num_windows']\n",
    "\n",
    "        if file_idx == -1:\n",
    "            raise IndexError(\"Index out of bounds for dataset.\")\n",
    "\n",
    "        meta = self.file_metadata[file_idx]\n",
    "\n",
    "        # 1. Randomly select window length\n",
    "        window_length = np.random.choice(self.valid_window_sizes)\n",
    "\n",
    "        # 2. Window selection strategy: base start point aligned with step size + random offset\n",
    "        base_start = local_idx * self.step_size\n",
    "        max_possible_start = max(0, meta['length'] - window_length)\n",
    "        random_offset = np.random.randint(0, self.step_size)\n",
    "        start = min(base_start + random_offset, max_possible_start)\n",
    "        end = start + window_length\n",
    "\n",
    "        if end > meta['length']:\n",
    "            end = meta['length']\n",
    "            start = max(0, end - window_length)\n",
    "\n",
    "        input_data_np = self.input_memmaps[file_idx][:, start:end]\n",
    "        output_data_np = self.output_memmaps[file_idx][:, start:end]\n",
    "\n",
    "        input_window = torch.from_numpy(input_data_np).float()\n",
    "        output_window = torch.from_numpy(output_data_np).float()\n",
    "\n",
    "        # Assuming label is in the first channel\n",
    "        if output_window.shape[0] > 1:\n",
    "            output_window = output_window[0:1, :]\n",
    "\n",
    "        # 3. Data Augmentation\n",
    "        if np.random.rand() < self.transform_prob:\n",
    "            # Random Scaling\n",
    "            scale_factor = np.random.uniform(self.scale_range[0], self.scale_range[1])\n",
    "            input_window = input_window * scale_factor\n",
    "\n",
    "            # Randomly add noise\n",
    "            if self.channel_wise_noise_stds is not None:\n",
    "                # noise_scale is expected to be a tensor of shape (C, 1) or (C)\n",
    "                noise_scale = self.channel_wise_noise_stds.to(input_window.device)\n",
    "                if noise_scale.dim() == 1:\n",
    "                    noise_scale = noise_scale.unsqueeze(-1) # (C, 1)\n",
    "                \n",
    "                # Expand noise_scale to match input_window.shape[1] for broadcasting\n",
    "                noise = torch.randn_like(input_window) * noise_scale\n",
    "            else:\n",
    "                noise = torch.randn_like(input_window) * self.noise_stds\n",
    "\n",
    "            input_window = input_window + noise\n",
    "\n",
    "            # Apply time warping\n",
    "            input_window, output_window = self._time_warp(input_window, output_window)\n",
    "\n",
    "        # Ensure output_window length matches input_window length (time axis)\n",
    "        if input_window.shape[-1] != output_window.shape[-1]:\n",
    "             min_len = min(input_window.shape[-1], output_window.shape[-1])\n",
    "             input_window = input_window[..., :min_len]\n",
    "             output_window = output_window[..., :min_len]\n",
    "\n",
    "        return input_window, output_window, input_window.shape[-1], output_window.shape[-1]\n",
    "\n",
    "\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, input_files, output_files, chunk_size=1000):\n",
    "        self.input_files = input_files\n",
    "        self.output_files = output_files\n",
    "        assert len(self.input_files) == len(self.output_files), \"Input and output file counts mismatch.\"\n",
    "        \n",
    "        self.chunk_size = chunk_size\n",
    "        self.data_chunks = []\n",
    "\n",
    "        # Load data and split into chunks\n",
    "        for i, (input_file, output_file) in enumerate(zip(self.input_files, self.output_files)):\n",
    "            inp_full_np = np.load(input_file)\n",
    "            out_full_np = np.load(output_file)\n",
    "\n",
    "            min_len = min(inp_full_np.shape[1], out_full_np.shape[1])\n",
    "            input_full_np = inp_full_np[:, :min_len]\n",
    "            output_full_np = out_full_np[:, :min_len]\n",
    "\n",
    "            # Assuming label is in the first channel\n",
    "            if output_full_np.shape[0] > 1:\n",
    "                output_full_np = output_full_np[0:1, :]\n",
    "\n",
    "            total_input_len = input_full_np.shape[1]\n",
    "            \n",
    "            for start_idx in range(0, total_input_len, chunk_size):\n",
    "                end_idx = min(start_idx + chunk_size, total_input_len)\n",
    "                \n",
    "                input_chunk = torch.from_numpy(input_full_np[:, start_idx:end_idx]).float()\n",
    "                output_chunk = torch.from_numpy(output_full_np[:, start_idx:end_idx]).float()\n",
    "                \n",
    "                self.data_chunks.append((input_chunk, output_chunk, input_chunk.shape[1], output_chunk.shape[1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_chunks[idx]\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, outputs, input_lengths_orig, output_lengths_orig = zip(*batch)\n",
    "    \n",
    "    input_lengths = list(input_lengths_orig)\n",
    "    output_lengths = list(output_lengths_orig)\n",
    "    \n",
    "    max_input_len = max(input_lengths)\n",
    "    padded_inputs = torch.stack([\n",
    "        torch.nn.functional.pad(x, (0, max_input_len - x.shape[-1])) \n",
    "        for x in inputs\n",
    "    ])\n",
    "    \n",
    "    max_output_len = max(output_lengths)\n",
    "    padded_outputs = torch.stack([\n",
    "        torch.nn.functional.pad(y, (0, max_output_len - y.shape[-1]))\n",
    "        for y in outputs\n",
    "    ])\n",
    "    \n",
    "    return padded_inputs, padded_outputs, input_lengths, output_lengths\n",
    "\n",
    "def calculate_classification_metrics_optimized(tp, fp, tn, fn, all_predictions_probs_flat, all_targets_flat):\n",
    "    \"\"\"\n",
    "    Calculates classification metrics using accumulated confusion matrix components.\n",
    "    Includes ROC AUC calculation which still requires all probabilities and targets.\n",
    "    \"\"\"\n",
    "    # Calculate F1, Precision, Recall from TP, FP, TN, FN\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    \n",
    "    # ROC AUC calculation\n",
    "    if len(np.unique(all_targets_flat)) > 1 and len(all_predictions_probs_flat) > 0:\n",
    "        roc_auc = roc_auc_score(all_targets_flat, all_predictions_probs_flat)\n",
    "    else:\n",
    "        roc_auc = float('nan') \n",
    "\n",
    "    return f1, precision, recall, roc_auc\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, num_output_channels, device, threshold=0.5, max_auc_samples=500000):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_valid_elements = 0\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    all_valid_predictions_probs_for_auc = []\n",
    "    all_valid_targets_for_auc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar_val = tqdm(dataloader, desc=\"Validation\")\n",
    "        for batch in progress_bar_val:\n",
    "            inputs, targets, input_lengths, output_lengths = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            targets = targets.float()\n",
    "\n",
    "            predictions_logits = model(inputs, original_lengths=input_lengths)\n",
    "            \n",
    "            max_output_len = predictions_logits.size(-1)\n",
    "            # Get time mask for valid output elements\n",
    "            output_mask_batch_time = create_mask(\n",
    "                [min(l, max_output_len) for l in output_lengths], \n",
    "                max_output_len,\n",
    "                device\n",
    "            )\n",
    "\n",
    "            # Mask only along the time dimension (C=1 here)\n",
    "            expanded_output_mask = output_mask_batch_time.unsqueeze(1) \n",
    "\n",
    "            predictions_logits_flat = predictions_logits.flatten()\n",
    "            targets_flat = targets.flatten()\n",
    "\n",
    "            # Flatten mask and select valid elements\n",
    "            valid_elements_mask_flat = (~expanded_output_mask).flatten()\n",
    "\n",
    "            valid_predictions_logits = predictions_logits_flat[valid_elements_mask_flat]\n",
    "            valid_targets = targets_flat[valid_elements_mask_flat]\n",
    "\n",
    "            if valid_targets.numel() > 0:\n",
    "                loss_tensor = criterion(valid_predictions_logits, valid_targets)\n",
    "                loss = loss_tensor.mean()\n",
    "                total_loss += loss.item() * valid_targets.numel()\n",
    "                total_valid_elements += valid_targets.numel()\n",
    "\n",
    "                valid_predictions_probs = torch.sigmoid(valid_predictions_logits)\n",
    "                valid_predictions_binary = (valid_predictions_probs >= threshold).int()\n",
    "\n",
    "                true_positives += ((valid_predictions_binary == 1) & (valid_targets == 1)).sum().item()\n",
    "                false_positives += ((valid_predictions_binary == 1) & (valid_targets == 0)).sum().item()\n",
    "                true_negatives += ((valid_predictions_binary == 0) & (valid_targets == 0)).sum().item()\n",
    "                false_negatives += ((valid_predictions_binary == 0) & (valid_targets == 1)).sum().item()\n",
    "\n",
    "                # --- Sampling for AUC START ---\n",
    "                current_batch_size_valid = valid_targets.numel()\n",
    "                if len(all_valid_predictions_probs_for_auc) < max_auc_samples:\n",
    "                    # If total samples below limit, add all\n",
    "                    all_valid_predictions_probs_for_auc.extend(valid_predictions_probs.cpu().tolist())\n",
    "                    all_valid_targets_for_auc.extend(valid_targets.cpu().tolist())\n",
    "                elif current_batch_size_valid > 0:\n",
    "                    # If over limit, randomly sample a fraction from current batch\n",
    "                    num_to_sample = min(current_batch_size_valid, max_auc_samples // 10)\n",
    "                    if num_to_sample > 0:\n",
    "                        indices = torch.randperm(current_batch_size_valid)[:num_to_sample]\n",
    "                        all_valid_predictions_probs_for_auc.extend(valid_predictions_probs[indices].cpu().tolist())\n",
    "                        all_valid_targets_for_auc.extend(valid_targets[indices].cpu().tolist())\n",
    "                        \n",
    "                        if len(all_valid_predictions_probs_for_auc) > max_auc_samples:\n",
    "                            # Keep only the latest samples up to max_auc_samples\n",
    "                            all_valid_predictions_probs_for_auc = all_valid_predictions_probs_for_auc[-max_auc_samples:]\n",
    "                            all_valid_targets_for_auc = all_valid_targets_for_auc[-max_auc_samples:]\n",
    "                # --- Sampling for AUC END ---\n",
    "\n",
    "            else:\n",
    "                loss = torch.tensor(0.0).to(device)\n",
    "\n",
    "    avg_loss = total_loss / (total_valid_elements + 1e-8) if total_valid_elements > 0 else float('nan')\n",
    "    \n",
    "    sampled_probs_np = np.array(all_valid_predictions_probs_for_auc)\n",
    "    sampled_targets_np = np.array(all_valid_targets_for_auc)\n",
    "\n",
    "    f1, precision, recall, roc_auc = calculate_classification_metrics_optimized(\n",
    "        true_positives, false_positives, true_negatives, false_negatives,\n",
    "        sampled_probs_np, sampled_targets_np\n",
    "    )\n",
    "    \n",
    "    return avg_loss, f1, precision, recall, roc_auc\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, train_f1_scores, val_f1_scores,\n",
    "                 train_precisions, val_precisions, train_recalls, val_recalls,\n",
    "                 train_roc_aucs, val_roc_aucs,\n",
    "                 num_epochs, save_dir=\".\"):\n",
    "    \n",
    "    epochs = range(1, num_epochs + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('Training and Validation Metrics per Epoch', fontsize=16)\n",
    "\n",
    "    # Loss Plot\n",
    "    axes[0, 0].plot(epochs, train_losses, label='Training Loss')\n",
    "    # Filter out NaNs for plotting if validation was skipped\n",
    "    valid_val_losses = [l for l in val_losses if not math.isnan(l)]\n",
    "    axes[0, 0].plot(range(1, len(valid_val_losses) + 1), valid_val_losses, label='Validation Loss')\n",
    "    axes[0, 0].set_title('Binary Cross Entropy Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "\n",
    "    # F1 Plot\n",
    "    axes[0, 1].plot(epochs, train_f1_scores, label='Training F1-score', color='orange')\n",
    "    valid_val_f1_scores = [l for l in val_f1_scores if not math.isnan(l)]\n",
    "    axes[0, 1].plot(range(1, len(valid_val_f1_scores) + 1), valid_val_f1_scores, label='Validation F1-score', color='red')\n",
    "    axes[0, 1].set_title('F1-score')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('F1-score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "    # Precision Plot\n",
    "    axes[0, 2].plot(epochs, train_precisions, label='Training Precision', color='green', linestyle='--')\n",
    "    valid_val_precisions = [l for l in val_precisions if not math.isnan(l)]\n",
    "    axes[0, 2].plot(range(1, len(valid_val_precisions) + 1), valid_val_precisions, label='Validation Precision', color='green')\n",
    "    axes[0, 2].set_title('Precision')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Precision')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True)\n",
    "\n",
    "    # Recall Plot\n",
    "    axes[1, 0].plot(epochs, train_recalls, label='Training Recall', color='purple', linestyle='--')\n",
    "    valid_val_recalls = [l for l in val_recalls if not math.isnan(l)]\n",
    "    axes[1, 0].plot(range(1, len(valid_val_recalls) + 1), valid_val_recalls, label='Validation Recall', color='purple')\n",
    "    axes[1, 0].set_title('Recall')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Recall')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "\n",
    "    # ROC AUC Plot\n",
    "    axes[1, 1].plot(epochs, train_roc_aucs, label='Training ROC AUC', color='brown', linestyle='--')\n",
    "    valid_val_roc_aucs = [l for l in val_roc_aucs if not math.isnan(l)]\n",
    "    axes[1, 1].plot(range(1, len(valid_val_roc_aucs) + 1), valid_val_roc_aucs, label='Validation ROC AUC', color='brown')\n",
    "    axes[1, 1].set_title('ROC AUC')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('ROC AUC Score')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    axes[1, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(save_dir, 'classification_metrics_combined.png'))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82840ebb-99ac-4644-b080-863680814ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dynamic STD Calculation and Data Splitting ---\n",
    "\n",
    "# Root directories for data\n",
    "MEG_ROOT = \"./libribrain/data/meg_data_npy\"\n",
    "LABEL_ROOT = \"./libribrain/data/labels_npy\"\n",
    "# Set the validation split ratio (0.0 means all data is used for training)\n",
    "VALIDATION_SPLIT = 0.2 \n",
    "NUM_CHANNELS = 48 # Fixed number of channels\n",
    "\n",
    "# Get all file pairs\n",
    "input_files = sorted([os.path.join(MEG_ROOT, f) for f in os.listdir(MEG_ROOT) if f.endswith('.npy')])\n",
    "output_files = sorted([os.path.join(LABEL_ROOT, f) for f in os.listdir(LABEL_ROOT) if f.endswith('.npy')])\n",
    "\n",
    "# Ensure file counts match\n",
    "assert len(input_files) == len(output_files), \"Input and output file counts mismatch in directories\"\n",
    "\n",
    "# Pair files and shuffle\n",
    "file_pairs = list(zip(input_files, output_files))\n",
    "random.seed(42) # Ensure consistent split\n",
    "random.shuffle(file_pairs)\n",
    "\n",
    "num_total = len(file_pairs)\n",
    "# Calculate split, ensuring num_val is at least 0\n",
    "num_val = int(num_total * VALIDATION_SPLIT)\n",
    "num_val = max(0, num_val) \n",
    "num_train = num_total - num_val\n",
    "\n",
    "# Split the file pairs\n",
    "train_file_pairs = file_pairs[num_val:]\n",
    "val_file_pairs = file_pairs[:num_val]\n",
    "\n",
    "# Unzip the pairs\n",
    "train_input_files, train_output_files = zip(*train_file_pairs)\n",
    "if val_file_pairs:\n",
    "    val_input_files, val_output_files = zip(*val_file_pairs)\n",
    "else:\n",
    "    # Handle the case where num_val is 0\n",
    "    val_input_files, val_output_files = tuple(), tuple()\n",
    "\n",
    "print(f\"Total files: {num_total}, Train files: {num_train}, Validation files: {num_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1e1b6-26a2-41a9-b516-e3773ba9f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Dynamically Calculate Channel Standard Deviations (STD) on Training Set ---\n",
    "print(\"--- Calculating Channel Standard Deviations on Training Set ---\")\n",
    "channel_sum = np.zeros(NUM_CHANNELS, dtype=np.float64)\n",
    "channel_sq_sum = np.zeros(NUM_CHANNELS, dtype=np.float64)\n",
    "channel_count = np.zeros(NUM_CHANNELS, dtype=np.int64)\n",
    "\n",
    "for input_file in tqdm(train_input_files, desc=\"Processing MEG files for STD calculation\"):\n",
    "    # Use mmap_mode='r' to save memory\n",
    "    data = np.load(input_file, mmap_mode='r').astype(np.float64)\n",
    "    \n",
    "    if data.shape[0] != NUM_CHANNELS:\n",
    "        # Simple check for transposed data\n",
    "        if data.shape[1] == NUM_CHANNELS:\n",
    "            data = data.T\n",
    "        else:\n",
    "            print(f\"Warning: File {input_file} has unexpected shape {data.shape}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "    T = data.shape[1]\n",
    "    \n",
    "    channel_sum += np.sum(data, axis=1)\n",
    "    channel_sq_sum += np.sum(np.square(data), axis=1)\n",
    "    channel_count += T\n",
    "\n",
    "safe_channel_count = np.where(channel_count > 0, channel_count, 1)\n",
    "mean = channel_sum / safe_channel_count\n",
    "variance = (channel_sq_sum / safe_channel_count) - (mean**2)\n",
    "std = np.sqrt(np.maximum(variance, 0))\n",
    "\n",
    "# Convert to torch tensor for use in the dataset (C, 1)\n",
    "channel_stds = torch.from_numpy(std).float().unsqueeze(1)\n",
    "print(\"--- STD Calculation Complete ---\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f22db3-c252-4a76-8d4c-f0d1342eee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Dynamically Calculate Positive Weight (pos_weight) for Training Labels ---\n",
    "print(\"--- Calculating Positive Weight for Training Set Labels ---\")\n",
    "total_positive_samples = 0\n",
    "total_negative_samples = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for output_file in tqdm(train_output_files, desc=\"Processing Label files for pos_weight\"):\n",
    "    # Label files should match MEG length\n",
    "    label_data = np.load(output_file, mmap_mode='r').astype(np.float32)\n",
    "    \n",
    "    # Assuming labels are (C, T) and we only care about the first channel\n",
    "    if label_data.ndim == 2:\n",
    "        label_data = label_data[0, :] if label_data.shape[0] > 0 else label_data.flatten()\n",
    "    \n",
    "    # Labels should be 0 or 1\n",
    "    total_positive_samples += np.sum(label_data == 1)\n",
    "    total_negative_samples += np.sum(label_data == 0)\n",
    "\n",
    "if total_positive_samples > 0:\n",
    "    # pos_weight = Num_Negative / Num_Positive\n",
    "    pos_weight_value = total_negative_samples / total_positive_samples\n",
    "else:\n",
    "    # Extreme case: no positive samples. Set to 1.0 (or a large number, but 1.0 is safer if training will continue)\n",
    "    pos_weight_value = 1.0 \n",
    "    print(\"Warning: No positive samples found in the training set labels! pos_weight set to 1.0.\")\n",
    "\n",
    "pos_weight = torch.tensor([pos_weight_value]).to(device)\n",
    "print(f\"Total Positive Samples in Train Set: {total_positive_samples}\")\n",
    "print(f\"Total Negative Samples in Train Set: {total_negative_samples}\")\n",
    "print(f\"Calculated pos_weight_value: {pos_weight_value:.6f}\")\n",
    "print(\"--- Pos Weight Calculation Complete ---\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33809b3c-ffd7-4393-8c5b-7f5845ef654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Create Dataset and Dataloader ---\n",
    "\n",
    "# Create training dataset and dataloader\n",
    "dataset = ClassificationDataset(\n",
    "    list(train_input_files), \n",
    "    list(train_output_files), \n",
    "    min_window=1000, \n",
    "    max_window=5000, \n",
    "    step_size=1200, \n",
    "    channel_wise_noise_stds=(channel_stds * 0.1) # Use calculated STD for noise scaling\n",
    ")\n",
    "dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=16, shuffle=True, num_workers=4, pin_memory=True) \n",
    "\n",
    "# Create validation dataset and dataloader (conditional on split)\n",
    "validation_dataloader = None \n",
    "if num_val > 0:\n",
    "    validation_dataset = ValidationDataset(list(val_input_files), list(val_output_files))\n",
    "    validation_dataloader = DataLoader(validation_dataset, collate_fn=collate_fn, batch_size=16, shuffle=False)\n",
    "    print(\"Validation Dataloader created.\")\n",
    "else:\n",
    "    print(\"Validation split is 0, skipping Validation Dataloader creation.\")\n",
    "\n",
    "# --- Model and Training Setup ---\n",
    "\n",
    "num_epochs = 100\n",
    "best_roc_auc = -1.0\n",
    "\n",
    "# Model parameters\n",
    "model_params = {\n",
    "    'input_channels': 48,\n",
    "    'sampling_rate': 250,\n",
    "    'encoder_dimension': 16,\n",
    "    'encoder_n_filters': 8,\n",
    "    'encoder_ratios': [5, 5, 2],\n",
    "    'transformer_n_heads': 4,\n",
    "    'transformer_n_layers': 1,\n",
    "    'transformer_dim_feedforward': 64,\n",
    "    'transformer_dropout': 0.1,\n",
    "    'decoder_out_channels': 1,\n",
    "    'activation': 'GELU',\n",
    "    'activation_params': {},\n",
    "    'norm': 'InstanceNorm1d',\n",
    "    'norm_params': {},\n",
    "    'n_residual_layers': 1,\n",
    "    'kernel_size': 7,\n",
    "    'last_kernel_size': 7,\n",
    "    'residual_kernel_size': 3,\n",
    "    'dilation_base': 2,\n",
    "    'compress': 2,\n",
    "    'true_skip': False\n",
    "}\n",
    "model = SEANetTransformerClassifier(**model_params).to(device).float()\n",
    "\n",
    "# Use dynamically calculated pos_weight\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.5, min_lr=1e-8)\n",
    "num_channels = model_params['decoder_out_channels']\n",
    "\n",
    "# Metric tracking lists\n",
    "train_losses = []\n",
    "train_f1_scores = []\n",
    "train_precisions = []\n",
    "train_recalls = []\n",
    "train_roc_aucs = []\n",
    "\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_roc_aucs = []\n",
    "\n",
    "classification_threshold = 0.5\n",
    "max_auc_samples = 50000 \n",
    "\n",
    "# --- Training Loop ---\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    running_loss_sum = 0.0\n",
    "    total_train_valid_elements = 0\n",
    "    \n",
    "    train_true_positives = 0\n",
    "    train_false_positives = 0\n",
    "    train_true_negatives = 0\n",
    "    train_false_negatives = 0\n",
    "\n",
    "    all_train_valid_predictions_probs_for_auc = []\n",
    "    all_train_valid_targets_for_auc = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        inputs, targets, input_lengths, output_lengths = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions_logits = model(inputs, original_lengths=input_lengths)\n",
    "        \n",
    "        max_output_len = predictions_logits.size(-1)\n",
    "        output_mask_batch_time = create_mask(\n",
    "            [min(l, max_output_len) for l in output_lengths], \n",
    "            max_output_len,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        expanded_output_mask = output_mask_batch_time.unsqueeze(1) \n",
    "\n",
    "        predictions_logits_flat = predictions_logits.flatten()\n",
    "        targets_flat = targets.flatten()\n",
    "\n",
    "        valid_elements_mask_flat = (~expanded_output_mask).flatten()\n",
    "\n",
    "        valid_predictions_logits = predictions_logits_flat[valid_elements_mask_flat]\n",
    "        valid_targets = targets_flat[valid_elements_mask_flat]\n",
    "\n",
    "        if valid_targets.numel() > 0:\n",
    "            loss = criterion(valid_predictions_logits, valid_targets).mean()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss_sum += loss.item() * valid_targets.numel()\n",
    "            total_train_valid_elements += valid_targets.numel()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                valid_predictions_probs = torch.sigmoid(valid_predictions_logits)\n",
    "                valid_predictions_binary = (valid_predictions_probs >= classification_threshold).int()\n",
    "\n",
    "                train_true_positives += ((valid_predictions_binary == 1) & (valid_targets == 1)).sum().item()\n",
    "                train_false_positives += ((valid_predictions_binary == 1) & (valid_targets == 0)).sum().item()\n",
    "                train_true_negatives += ((valid_predictions_binary == 0) & (valid_targets == 0)).sum().item()\n",
    "                train_false_negatives += ((valid_predictions_binary == 0) & (valid_targets == 1)).sum().item()\n",
    "\n",
    "                if len(all_train_valid_predictions_probs_for_auc) < max_auc_samples:\n",
    "                    all_train_valid_predictions_probs_for_auc.extend(valid_predictions_probs.cpu().tolist())\n",
    "                    all_train_valid_targets_for_auc.extend(valid_targets.cpu().tolist())\n",
    "        else:\n",
    "            loss = torch.tensor(0.0).to(device)\n",
    "            \n",
    "        avg_loss_display = running_loss_sum / (total_train_valid_elements + 1e-8)\n",
    "        progress_bar.set_postfix(\n",
    "            loss=loss.item(),\n",
    "            avg_loss=avg_loss_display\n",
    "        )\n",
    "            \n",
    "    epoch_avg_loss = running_loss_sum / (total_train_valid_elements + 1e-8) if total_train_valid_elements > 0 else float('nan')\n",
    "\n",
    "    train_f1, train_precision, train_recall, train_roc_auc = calculate_classification_metrics_optimized(\n",
    "        train_true_positives, train_false_positives, train_true_negatives, train_false_negatives,\n",
    "        np.array(all_train_valid_predictions_probs_for_auc),\n",
    "        np.array(all_train_valid_targets_for_auc)\n",
    "    )\n",
    "    \n",
    "    train_losses.append(epoch_avg_loss)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    train_precisions.append(train_precision)\n",
    "    train_recalls.append(train_recall)\n",
    "    train_roc_aucs.append(train_roc_auc)\n",
    "\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{num_epochs} Training Summary ---\")\n",
    "    print(f\"Train Average Loss (BCE): {epoch_avg_loss:.6f}\")\n",
    "    print(f\"Train F1-score: {train_f1:.6f}\")\n",
    "    print(f\"Train Precision: {train_precision:.6f}\")\n",
    "    print(f\"Train Recall: {train_recall:.6f}\")\n",
    "    print(f\"Train ROC AUC (Sampled): {train_roc_auc:.6f}\")\n",
    "\n",
    "    # --- Validation Phase (Conditional) ---\n",
    "    if validation_dataloader is not None:\n",
    "        val_loss, val_f1, val_precision, val_recall, val_roc_auc = evaluate_model(\n",
    "            model, validation_dataloader, criterion, num_channels, device, classification_threshold, max_auc_samples=500000)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_roc_aucs.append(val_roc_auc)\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} Validation Summary ---\")\n",
    "        print(f\"Validation BCE Loss: {val_loss:.6f}\")\n",
    "        print(f\"Validation F1-score: {val_f1:.6f}\")\n",
    "        print(f\"Validation Precision: {val_precision:.6f}\")\n",
    "        print(f\"Validation Recall: {val_recall:.6f}\")\n",
    "        print(f\"Validation ROC AUC: {val_roc_auc:.6f}\")\n",
    "        print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Step scheduler based on validation metric\n",
    "        scheduler.step(val_roc_auc) \n",
    "\n",
    "        # Save best model\n",
    "        if val_roc_auc > best_roc_auc:\n",
    "            best_roc_auc = val_roc_auc\n",
    "            os.makedirs(\"./libribrain\", exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"./libribrain/speech_detection.pth\")\n",
    "            print(f\"New best model saved with validation ROC AUC: {best_roc_auc:.6f}\")\n",
    "            \n",
    "    else:\n",
    "        # If no validation data, step scheduler based on training F1 (or just skip/use loss)\n",
    "        print(\"\\nSkipping validation and scheduler step based on validation (VALIDATION_SPLIT = 0).\")\n",
    "        scheduler.step(train_f1) # Using training F1 to still allow LR decay\n",
    "        \n",
    "        # Append NaN values to keep metric lists the same length as epochs for plotting\n",
    "        val_losses.append(float('nan'))\n",
    "        val_f1_scores.append(float('nan'))\n",
    "        val_precisions.append(float('nan'))\n",
    "        val_recalls.append(float('nan'))\n",
    "        val_roc_aucs.append(float('nan'))\n",
    "        \n",
    "print(\"\\nTraining complete!\")\n",
    "torch.save(model.state_dict(), f\"./libribrain/speech_detection_final.pth\")\n",
    "os.makedirs(\"./libribrain\", exist_ok=True)\n",
    "plot_metrics(train_losses, val_losses, train_f1_scores, val_f1_scores,\n",
    "             train_precisions, val_precisions, train_recalls, val_recalls,\n",
    "             train_roc_aucs, val_roc_aucs,\n",
    "             num_epochs, save_dir=\"./libribrain/\")\n",
    "print(f\"Combined classification metrics plot saved to ./libribrain/classification_metrics_combined.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4daae-9d5c-46dc-9b3d-ef1bc29e953b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
